{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,signal\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "import numpy as np                                       # fast vectors and matrices\n",
    "import matplotlib.pyplot as plt                          # plotting\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import conv1d, mse_loss\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# For the dataloading\n",
    "from torch.utils.data import Dataset\n",
    "from abc import abstractmethod\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from nnAudio import Spectrogram\n",
    "from scipy.io import wavfile\n",
    "import soundfile\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PianoRollAudioDataset(Dataset):\n",
    "    def __init__(self, path, groups=None, sequence_length=None, seed=42, refresh=False, device='cpu'):\n",
    "        self.path = path\n",
    "        self.groups = groups if groups is not None else self.available_groups()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.device = device\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.refresh = refresh\n",
    "\n",
    "        self.data = []\n",
    "        print(f\"Loading {len(groups)} group{'s' if len(groups) > 1 else ''} \"\n",
    "              f\"of {self.__class__.__name__} at {path}\")\n",
    "        for group in groups:\n",
    "            for input_files in tqdm(self.files(group), desc='Loading group %s' % group): #self.files is defined in MAPS class\n",
    "                self.data.append(self.load(*input_files)) # self.load is a function defined below. It first loads all data into memory first\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        data = self.data[index]\n",
    "        result = dict(path=data['path'])\n",
    "\n",
    "        audio_length = len(data['audio'])\n",
    "        step_begin = self.random.randint(audio_length - self.sequence_length) // HOP_LENGTH\n",
    "        n_steps = self.sequence_length // HOP_LENGTH\n",
    "        step_end = step_begin + n_steps\n",
    "\n",
    "        begin = step_begin * HOP_LENGTH\n",
    "        end = begin + self.sequence_length\n",
    "\n",
    "        result['audio'] = data['audio'][begin:end]\n",
    "        result['label'] = data['label'][step_begin:step_end, :]\n",
    "        result['velocity'] = data['velocity'][step_begin:step_end, :]\n",
    "\n",
    "\n",
    "        result['audio'] = result['audio'].float().div_(32768.0) # converting to float by dividing it by 2^15\n",
    "        result['frame'] = (result['label'] > 1).float()\n",
    "        # print(f\"result['audio'].shape = {result['audio'].shape}\")\n",
    "        # print(f\"result['label'].shape = {result['label'].shape}\")\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @classmethod # This one seems optional?\n",
    "    @abstractmethod # This is to make sure other subclasses also contain this method\n",
    "    def available_groups(cls):\n",
    "        \"\"\"return the names of all available groups\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def files(self, group):\n",
    "        \"\"\"return the list of input files (audio_filename, tsv_filename) for this group\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load(self, audio_path, tsv_path):\n",
    "        \"\"\"\n",
    "        load an audio track and the corresponding labels\n",
    "        Returns\n",
    "        -------\n",
    "            A dictionary containing the following data:\n",
    "            path: str\n",
    "                the path to the audio file\n",
    "            audio: torch.ShortTensor, shape = [num_samples]\n",
    "                the raw waveform\n",
    "            label: torch.ByteTensor, shape = [num_steps, midi_bins]\n",
    "                a matrix that contains the onset/offset/frame labels encoded as:\n",
    "                3 = onset, 2 = frames after onset, 1 = offset, 0 = all else\n",
    "            velocity: torch.ByteTensor, shape = [num_steps, midi_bins]\n",
    "                a matrix that contains MIDI velocity values at the frame locations\n",
    "        \"\"\"\n",
    "        saved_data_path = audio_path.replace('.flac', '.pt').replace('.wav', '.pt')\n",
    "        if os.path.exists(saved_data_path) and self.refresh==False: # Check if .pt files exist, if so just load the files\n",
    "            return torch.load(saved_data_path)\n",
    "        # Otherwise, create the .pt files\n",
    "        audio, sr = soundfile.read(audio_path, dtype='int16')\n",
    "#         audio, sr = wavfile.read(audio_path)\n",
    "        assert sr == SAMPLE_RATE\n",
    "\n",
    "        audio = torch.ShortTensor(audio) # convert numpy array to pytorch tensor\n",
    "        audio_length = len(audio)\n",
    "\n",
    "        n_keys = MAX_MIDI - MIN_MIDI + 1\n",
    "        n_steps = (audio_length - 1) // HOP_LENGTH + 1 # This will affect the labels time steps\n",
    "\n",
    "        label = torch.zeros(n_steps, n_keys, dtype=torch.uint8)\n",
    "        velocity = torch.zeros(n_steps, n_keys, dtype=torch.uint8)\n",
    "\n",
    "        tsv_path = tsv_path\n",
    "        midi = np.loadtxt(tsv_path, delimiter='\\t', skiprows=1)\n",
    "\n",
    "        for onset, offset, note, vel in midi:\n",
    "            left = int(round(onset * SAMPLE_RATE / HOP_LENGTH)) # Convert time to time step\n",
    "            onset_right = min(n_steps, left + HOPS_IN_ONSET) # Ensure the time step of onset would not exceed the last time step\n",
    "            frame_right = int(round(offset * SAMPLE_RATE / HOP_LENGTH))\n",
    "            frame_right = min(n_steps, frame_right) # Ensure the time step of frame would not exceed the last time step\n",
    "            offset_right = min(n_steps, frame_right + HOPS_IN_OFFSET)\n",
    "\n",
    "            f = int(note) - MIN_MIDI\n",
    "            label[left:onset_right, f] = 3\n",
    "            label[onset_right:frame_right, f] = 2\n",
    "            label[frame_right:offset_right, f] = 1\n",
    "            velocity[left:frame_right, f] = vel\n",
    "\n",
    "        data = dict(path=audio_path, audio=audio, label=label, velocity=velocity)\n",
    "#         torch.save(data, saved_data_path)\n",
    "        return data\n",
    "\n",
    "class MusicNet(PianoRollAudioDataset):\n",
    "    def __init__(self, path='../IJCNN2020_music_transcription/data/', groups=None, sequence_length=None, seed=42, refresh=False, device='cpu'):\n",
    "        super().__init__(path, groups if groups is not None else ['train'], sequence_length, seed, refresh, device)\n",
    "\n",
    "    @classmethod\n",
    "    def available_groups(cls):\n",
    "        return ['train', 'test']\n",
    "\n",
    "    def files(self, group):\n",
    "\n",
    "        wavs = sorted(glob(os.path.join(self.path, f'{group}_data/*.wav')))\n",
    "        tsvs = sorted(glob(os.path.join(self.path, f'tsv_{group}_labels/*.tsv')))\n",
    "        assert(all(os.path.isfile(wav) for wav in wavs))\n",
    "\n",
    "        return zip(wavs, tsvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "HOP_LENGTH = 512\n",
    "ONSET_LENGTH = 512\n",
    "OFFSET_LENGTH = 512\n",
    "HOPS_IN_ONSET = ONSET_LENGTH // HOP_LENGTH\n",
    "HOPS_IN_OFFSET = OFFSET_LENGTH // HOP_LENGTH\n",
    "SAMPLE_RATE = 44100\n",
    "MIN_MIDI = 21\n",
    "MAX_MIDI = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading group train: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 group of MusicNet at ./data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading group train: 320it [01:41,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "train_set = MusicNet(path='./data/', groups=['train'], sequence_length=327680, refresh=True)\n",
    "loading_time = time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 19.1567 seconds\n"
     ]
    }
   ],
   "source": [
    "factor = 4\n",
    "n_fft = 4096//factor\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "Loss = torch.nn.BCELoss()\n",
    "def L(yhatvar,y):\n",
    "    return Loss(yhatvar,y) * 128/2\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        f_kernal = 128//factor\n",
    "        self.STFT_layer = Spectrogram.STFT(sr=44100, n_fft=n_fft, hop_length=HOP_LENGTH, pad_mode='constant', center=True)\n",
    "        self.freq_cnn1 = torch.nn.Conv2d(1,4, (f_kernal,3), stride=(8,1), padding=1)\n",
    "        self.freq_cnn2 = torch.nn.Conv2d(4,8, (f_kernal,3), stride=(8,1), padding=1)\n",
    "        shape = self.shape_inference(f_kernal)\n",
    "        self.bilstm = torch.nn.LSTM(shape*8, shape*8, batch_first=True, bidirectional=True)\n",
    "        self.pitch_classifier = torch.nn.Linear(shape*8*2, 88)\n",
    "\n",
    "    def shape_inference(self, f_kernal):\n",
    "        layer1 = (n_fft//2+2-(f_kernal))//8 + 1 \n",
    "        layer2 = (layer1+2-(f_kernal))//8 + 1 \n",
    "        return layer2\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.STFT_layer(x[:,:-1])\n",
    "        x = torch.log(x+1e-5)\n",
    "        x = torch.relu(self.freq_cnn1(x.unsqueeze(1)))\n",
    "        x = torch.relu(self.freq_cnn2(x))\n",
    "        x, _ = self.bilstm(x.view(x.size(0), x.size(1)*x.size(2), x.size(3)).transpose(1,2))\n",
    "        x = torch.sigmoid(self.pitch_classifier(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn  = torch.nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\ttrain loss\ttime\n",
      "1\t0.680794\t2.675504                                                                                                                                                                                     \n",
      "2\t0.654296\t2.190073                                                                                                                                                                                     \n",
      "3\t0.625197\t2.190599                                                                                                                                                                                     \n",
      "4\t0.592302\t1.988118                                                                                                                                                                                     \n",
      "5\t0.557689\t2.366848                                                                                                                                                                                     \n",
      "6\t0.523040\t2.158864                                                                                                                                                                                     \n",
      "7\t0.488986\t2.252998                                                                                                                                                                                     \n",
      "8\t0.455154\t2.142213                                                                                                                                                                                     \n",
      "9\t0.425335\t2.354955                                                                                                                                                                                     \n",
      "10\t0.396648\t2.234262                                                                                                                                                                                    \n",
      "11\t0.365067\t2.367327                                                                                                                                                                                    \n",
      "12\t0.337991\t2.296782                                                                                                                                                                                    \n",
      "13\t0.315885\t2.163382                                                                                                                                                                                    \n",
      "14\t0.297411\t2.308928                                                                                                                                                                                    \n",
      "15\t0.281475\t2.080963                                                                                                                                                                                    \n",
      "16\t0.267162\t2.104033                                                                                                                                                                                    \n",
      "17\t0.257877\t2.148058                                                                                                                                                                                    \n",
      "18\t0.247001\t2.671651                                                                                                                                                                                    \n",
      "19\t0.238569\t2.339499                                                                                                                                                                                    \n",
      "20\t0.230749\t2.294941                                                                                                                                                                                    \n",
      "21\t0.224770\t2.082688                                                                                                                                                                                    \n",
      "22\t0.218323\t2.186359                                                                                                                                                                                    \n",
      "23\t0.211568\t1.952121                                                                                                                                                                                    \n",
      "24\t0.204761\t2.257179                                                                                                                                                                                    \n",
      "25\t0.200921\t2.059831                                                                                                                                                                                    \n",
      "26\t0.197360\t2.298704                                                                                                                                                                                    \n",
      "27\t0.192651\t2.128277                                                                                                                                                                                    \n",
      "28\t0.188044\t2.111091                                                                                                                                                                                    \n",
      "29\t0.185519\t2.260242                                                                                                                                                                                    \n",
      "30\t0.182316\t2.313159                                                                                                                                                                                    \n",
      "31\t0.178079\t2.191499                                                                                                                                                                                    \n",
      "32\t0.177188\t2.196004                                                                                                                                                                                    \n",
      "33\t0.174240\t2.286751                                                                                                                                                                                    \n",
      "34\t0.173150\t2.266993                                                                                                                                                                                    \n",
      "35\t0.169106\t2.053478                                                                                                                                                                                    \n",
      "36\t0.167142\t2.270150                                                                                                                                                                                    \n",
      "37\t0.165931\t2.107211                                                                                                                                                                                    \n",
      "38\t0.164126\t2.007153                                                                                                                                                                                    \n",
      "39\t0.160318\t2.039850                                                                                                                                                                                    \n",
      "40\t0.162131\t2.333723                                                                                                                                                                                    \n",
      "41\t0.157407\t2.281523                                                                                                                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\t0.156261\t2.117943                                                                                                                                                                                    \n",
      "43\t0.157839\t2.383978                                                                                                                                                                                    \n",
      "44\t0.159349\t2.153829                                                                                                                                                                                    \n",
      "45\t0.154421\t2.670984                                                                                                                                                                                    \n",
      "46\t0.154185\t2.505843                                                                                                                                                                                    \n",
      "47\t0.152815\t2.252491                                                                                                                                                                                    \n",
      "48\t0.150401\t2.103458                                                                                                                                                                                    \n",
      "49\t0.151906\t2.490398                                                                                                                                                                                    \n",
      "50\t0.149136\t2.369726                                                                                                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "epoches = 50\n",
    "\n",
    "times = []\n",
    "loss_histroy = []\n",
    "print(\"epoch\\ttrain loss\\ttime\")\n",
    "total_i = len(train_loader)\n",
    "for e in range(epoches):\n",
    "    running_loss = 0\n",
    "    start = time()\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(data['audio'].to(device))\n",
    "        loss = loss_fn(y_pred, data['frame'].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()        \n",
    "        \n",
    "        print(f\"Training {idx+1}/{total_i} batches\\t Loss: {loss.item()}\", end = '\\r')\n",
    "    time_used = time()-start\n",
    "    times.append(time_used)\n",
    "    print(' '*200, end='\\r')\n",
    "    print(f'{e+1}\\t{running_loss/total_i:.6f}\\t{time_used:.6f}')\n",
    "    loss_histroy.append(running_loss/total_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnAudio_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnAudio_result['loss_histroy'] = loss_histroy\n",
    "nnAudio_result['time_histroy'] = times\n",
    "nnAudio_result['loading_time'] = loading_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'./nnAudio_result_{n_fft}', 'wb') as f:\n",
    "    pickle.dump(nnAudio_result,f)\n",
    "    \n",
    "torch.save(model.state_dict(), f'./weight/nnAudio_result_{n_fft}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
