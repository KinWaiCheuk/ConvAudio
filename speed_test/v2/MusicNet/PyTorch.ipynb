{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import glob\n",
    "\n",
    "from nnAudio import Spectrogram\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicNet(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = glob.glob('./train_data/*.wav')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)  \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        audio_name = self.file_list[idx]\n",
    "        sr, wav = wavfile.read(audio_name)\n",
    "\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MusicNet('./train_data/')\n",
    "dataset = DataLoader(dataset, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT\n",
    "\n",
    "n_fft_ls = [256, 512, 1024, 2048, 4096]\n",
    "for n_fft in n_fft_ls:\n",
    "    layer = Spectrogram.STFT(n_fft=n_fft, hop_length=512, verbose=False, device=device)\n",
    "    start = time.time()\n",
    "    for i in tqdm.tqdm(dataset):\n",
    "        i = i.to(device)\n",
    "        layer(i)\n",
    "    result[f'STFT_{n_fft}'] = time.time()-start\n",
    "\n",
    "n_fft_ls = [256, 512, 1024, 2048, 4096]\n",
    "for n_fft in n_fft_ls:\n",
    "    layer = Spectrogram.STFT(n_fft=n_fft, hop_length=512, freq_scale='log', sr=44100, fmin=1, fmax=22050, verbose=False, device=device)\n",
    "    time.sleep(0.5)\n",
    "    start = time.time()\n",
    "    for i in tqdm.tqdm(dataset):\n",
    "        i = i.to(device)\n",
    "        layer(i)\n",
    "    result[f'STFT-log_{n_fft}'] = time.time()-start\n",
    "    \n",
    "\n",
    "# Mel\n",
    "\n",
    "n_fft_ls = [256, 512, 1024, 2048, 4096]\n",
    "for n_fft in n_fft_ls:\n",
    "    n_mels_ls = [128, 256, 512, 1024, 2048]\n",
    "    for n_mels in n_mels_ls:\n",
    "        if n_mels < n_fft:\n",
    "            layer = Spectrogram.MelSpectrogram(n_fft=n_fft, n_mels=n_mels, hop_length=512, verbose=False, device=device)\n",
    "            start = time.time()\n",
    "            for i in tqdm.tqdm(dataset):\n",
    "                i = i.to(device)\n",
    "                layer(i)\n",
    "            result[f'Mel-{n_fft}-n_bins{n_mels}'] = time.time()-start\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# CQT\n",
    "\n",
    "for r in range(1,11):\n",
    "    layer = Spectrogram.CQT1992v2(sr=44100, n_bins=84*r, bins_per_octave=12*r,hop_length=512,verbose=False,device=device)\n",
    "    start = time.time()\n",
    "    for i in tqdm.tqdm(dataset):\n",
    "        i = i.to(device)\n",
    "        layer(i)\n",
    "    result[f'CQT-r={r}'] = time.time()-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
