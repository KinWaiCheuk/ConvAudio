{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nnAudio\n",
    "nnAudio is an audio processing toolbox using PyTorch convolutional neural network as its backend. By doing so, spectrograms can be generated from audio on-the-fly during neural network training and the Fourier kernels (e.g. or CQT kernels) can be trained. [Kapre](https://github.com/keunwoochoi/kapre) has a similar concept in which they also use 1D convolutional neural network to extract spectrograms based on [Keras](https://keras.io).\n",
    "\n",
    "Other GPU audio processing tools are [torchaudio](https://github.com/pytorch/audio) and [tf.signal](https://www.tensorflow.org/api_docs/python/tf/signal). But they are not using the neural network approach, and hence the Fourier basis can not be trained. As of PyTorch 1.6.0, torchaudio is still very difficult to install under the Windows environment due to `sox`. nnAudio is a more compatible audio processing tool across different operating systems since it relies mostly on PyTorch convolutional neural network. The name of nnAudio comes from `torch.nn`\n",
    "\n",
    "\n",
    "## Documentation\n",
    "https://kinwaicheuk.github.io/nnAudio/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with other libraries\n",
    "| Feature | [nnAudio](https://github.com/KinWaiCheuk/nnAudio) | [torch.stft](https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/SpectralOps.cpp) | [kapre](https://github.com/keunwoochoi/kapre) | [torchaudio](https://github.com/pytorch/audio) | [tf.signal](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/ops/signal) | [torch-stft](https://github.com/pseeth/torch-stft) | [librosa](https://github.com/librosa/librosa) |\n",
    "| ------- | ------- | ---------- | ----- | ---------- | ---------------------------- | ---------- | ------- |\n",
    "| Trainable | ✅ | ❌| ✅ | ❌ | ❌ | ✅ | ❌ |\n",
    "| Differentiable | ✅  | ✅ | ✅ | ✅ | ✅ | ✅ | ❌ |\n",
    "| Linear frequency STFT| ✅  | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |\n",
    "| Logarithmic frequency STFT| ✅  | ❌ | ✅ | ❌ | ❌ | ❌ | ❌ |\n",
    "| Inverse STFT| ✅  | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |\n",
    "| Griffin-Lim| ✅  | ❌ | ❌ | ✅ | ✅ | ❌ | ✅ |\n",
    "| Mel | ✅ | ❌ | ✅ | ✅ | ✅ | ❌ | ✅ |\n",
    "| MFCC | ✅  | ❌ | ❌ | ✅| ✅ | ❌ | ✅ |\n",
    "| CQT | ✅ | ❌ | ❌ | ❌ | ❌ | ❌ | ✅ |\n",
    "| Gammatone | ☑️ | ❌ | ❌ | ❌ | ❌ | ❌ | ❌ |\n",
    "| CFP<sup>1</sup> | ☑️ | ❌ | ❌ | ❌ | ❌ | ❌ | ❌ |\n",
    "| GPU support | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ❌ |\n",
    "\n",
    "✅: Fully support    ☑️: Developing (only available in dev version)    ❌: Not support\n",
    "\n",
    "<sup>1</sup> [Combining Spectral and Temporal Representations for Multipitch Estimation of Polyphonic Music](https://ieeexplore.ieee.org/document/7118691)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News & Changelog\n",
    "**version 0.2.1a** (8 Nov 2020): \n",
    "Added two more spectrogram types `Gammatonegram()` and `Combined_Frequency_Periodicity()`. This version can be obtained via:\n",
    "\n",
    "`pip install git+https://github.com/KinWaiCheuk/nnAudio.git#subdirectory=Installation`.\n",
    "\n",
    "**version 0.2.0** (8 Nov 2020): \n",
    "Now it is possible to do `stft_layer.to(device)` to move the spectrogram layers between different devices.\n",
    "No more `device` argument when creating the spectrogram layers.\n",
    "\n",
    "To use this version, do `pip install nnAudio==0.2.0`.\n",
    "\n",
    "**version 0.1.5**:\n",
    "Much better `iSTFT` and `Griffin-Lim`. Now Griffin-Lim is a separated PyTorch class and requires `torch >= 1.6.0` to run. `STFT` has also been refactored and it is less memory consuming now.\n",
    "\n",
    "To use this version, do `pip install nnAudio==0.1.5`.\n",
    "\n",
    "**version 0.1.4a0**: Finalized `iSTFT` and `Griffin-Lim`. They are now more accurate and stable.\n",
    "\n",
    "**version 0.1.2.dev3**: Add `win_length` to `STFT` so that it has the same funcationality as librosa.\n",
    "\n",
    "**version 0.1.2.dev2**: Fix bugs where the inverse cannot be done using GPU. And add a separated `iSTFT` layer class\n",
    "\n",
    "**version 0.1.2.dev1**: Add Inverse STFT and Griffin-Lim. They are still under development, please use with care.\n",
    "                    \n",
    "**version 0.1.1**  (1 June 2020): Add MFCC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## How to cite nnAudio\n",
    "The paper for nnAudio is avaliable on [IEEE Access](https://ieeexplore.ieee.org/document/9174990)\n",
    "\n",
    "K. W. Cheuk, H. Anderson, K. Agres and D. Herremans, \"nnAudio: An on-the-Fly GPU Audio to Spectrogram Conversion Toolbox Using 1D Convolutional Neural Networks,\" in IEEE Access, vol. 8, pp. 161981-162003, 2020, doi: 10.1109/ACCESS.2020.3019084.\n",
    "\n",
    "### BibTex\n",
    "@ARTICLE{9174990,\n",
    "  author={K. W. {Cheuk} and H. {Anderson} and K. {Agres} and D. {Herremans}},\n",
    "  journal={IEEE Access}, \n",
    "  title={nnAudio: An on-the-Fly GPU Audio to Spectrogram Conversion Toolbox Using 1D Convolutional Neural Networks}, \n",
    "  year={2020},\n",
    "  volume={8},\n",
    "  number={},\n",
    "  pages={161981-162003},\n",
    "  doi={10.1109/ACCESS.2020.3019084}}\n",
    "\n",
    "\n",
    "## Call for Contributions\n",
    "nnAudio is a fast-growing package. With the increasing number of feature requests, we welcome anyone who is familiar with digital signal processing and neural network to contribute to nnAudio. The current list of pending features includes:\n",
    "1. Invertible Constant Q Transform (CQT)\n",
    "1. CQT with filter scale factor (see issue [#54](/../../issues/54))\n",
    "1. Variable Q Transform (see VQT[https://www.researchgate.net/publication/274009051_A_Matlab_Toolbox_for_Efficient_Perfect_Reconstruction_Time-Frequency_Transforms_with_Log-Frequency_Resolution])\n",
    "1. Speed and Performance improvements for Griffin-Lim (see issue [#41](/../../issues/41))\n",
    "1. Data Augmentation (see issue [#49](/../../issues/49))\n",
    "\n",
    "(Quick tips for unit test: `cd` inside Installation folder, then type `pytest`. You need at least 1931 MiB GPU memory to pass all the unit tests)\n",
    "\n",
    "Alternatively, you may also contribute by:\n",
    "   1. Refactoring the code structure (Now all functions are within the same file, but with the increasing number of features, I think we need to break it down into smaller modules)\n",
    "   1. Making a better demonstration code or tutorial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Dependencies\n",
    "Numpy 1.14.5\n",
    "\n",
    "Scipy 1.2.0\n",
    "\n",
    "PyTorch >= 1.6.0 (Griffin-Lim only available after 1.6.0)\n",
    "\n",
    "Python >= 3.6\n",
    "\n",
    "librosa = 0.7.0 (Theoretically nnAudio depends on librosa. But we only need to use a single function `mel` from `librosa.filters`. To save users troubles from installing librosa for this single function, I just copy the chunk of functions corresponding to `mel` in my code so that nnAudio runs without the need to install librosa)\n",
    "\n",
    "\n",
    "\n",
    "## Other similar libraries\n",
    "[Kapre](https://www.semanticscholar.org/paper/Kapre%3A-On-GPU-Audio-Preprocessing-Layers-for-a-of-Choi-Joo/b1ad5643e5dd66fac27067b00e5c814f177483ca?citingPapersSort=is-influential#citing-papers)\n",
    "\n",
    "[torch-stft](https://github.com/pseeth/torch-stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
